2017 10 25
Bienvenida al curso
	Vamos a ver:
		* Que es un datascientist?
		* En que temas se usa datascients
		* Logros de la ciencia de datos
		* Workflow tipico de una data scientist:
				- Formular una pregunta
				- Recopilar datos
				- Limpiar datos
				- Construir un modelo matemático
				- Validar el modelo
				- Comunicar resultados
				- Implementar sistemas ingenieriles para automatizar el trabajo


¿Qué es un Data Scientist?:
	Una persona que construye sistemas que intentan encontrar patrones en datos / William Wolf

	Son más que nada programadores.
	
	Esta persona entiende el core del negocio en el que trabaja y puede traducir los problemas del 
		negocio de la empresa en terminos matemáticos y cuando encuentra soluciones a estos issues
		los traduce en código, es decir crea un programa para automarizar esta solución.

	Para ser un data scientist:
		Hay que tener conocimiento de programación (los data scientist son más que nada programadores),
			conocimiento en matemáticas y debe tener experiencia en el negocio.

	Un data scientist sabe más de estadistica que un programador y más de programación que un
		estadistico.

	Es una persona que utiliza conocimientos del negocio, las estadísticas y la programación para 
		encontrar patrones que apoyen la toma de decisiones.



Ejemplos se uso de data science
	
	Coches autonomos (tesla)
		La red neuronal convolucional: Algoritmo que intenta imitar a lo que haga un ser humano mientras conduce.


 	Predecir crimen en Rio de janeiro
 		output: Lo que paso input: el contexto	



Cómo funciona una búsqueda de Google y el Algoritmo de Spotify

	¿Qué sucede cuando buscas en Google?
		Cuando buscas pasas un input de tu búsqueda y Google genera un output que es una lista ordenada que
			satisfacen tu búsqueda.

		Para generar esta lista Google dispone de un algoritmo que selecciona estas páginas entre millones de páginas.


	¿Cómo se personalizan tus playlist en Spotify?
		Dada la musica que has escuchado en el pasado sirve como input de machine learning que genera un
		output de música que podrían gustarte de acuerdo a esto.


	Recuerda: No siempre la parte más compleja es hacer un modelo matemático.



Retos de un data scientist

	Una semana típica de un data scientist:
		* Análisis exploratorio: Observar! Entender cuales son las causas del problema.

		* Construir un modelo matemático: Crear un modelo para automatizar el proceso de predecir el
				problema. Lapiz y papel.

		* Construir un sistema ingenieril para automatizar dicho modelo: Programar. Crear un programa para
				automatizar el modelo.

		* Coordinar con el negocio: Convencer a los gerentes que el modelo funciona y que la inversión va a
				ser fructifera.

		* Explicar resultados: a los involucrados en el tema. Esta explicación deber ser lo más clara
				posible teniendo en cuenta que las personas a las que vamos a explicar no son expertos en 
				matematicas ni programación.

		- No tienen que desarrollarse siempre todas estas cosas en una sola semana pero son las que se
			realizan.


	Un año típico:
		* Desarrollar relaciones: Con los gerentes o las personas necesarias , para empaparce del negocio
				y crear un ambiente de colaboración. No se trabaja solo.

		* Evangelizar una cultura de datos dentro de la empresa: Convencer que todos los datos son de
				utilidad cuando se usan de manera correcta. Una empresa tiene más posibilidades cuando 
				toma decisiones basadas en datos.

		* Construir herramientas de uso interno: ejemplo: dashboards. Construir herramientas que faciliten
				el trabajo de las personas de la empresa. 

		* Construir sistemas y features para usuarios externos: las listas personalizadas de spotify, las
				busquedas de google. Son las herramientas que se dirigen al cliente y que le dan un plus 
				a los servicios que presta la empresa.

		* Construir y mantener sistemas ingenieriles de ETL: Obtener datos de fuentes externas para poder
				usarlos en beneficio de la empresa. ETL (Extraer -extract-, Transformar -transform-, Cargar -load-)

				ETL pipeline: https://es.wikipedia.org/wiki/Extract,_transform_and_load


	- No es posible ser data scientist sin ser parte de una comunidad, dando y recibiendo conocimiento
		constantemente (hay que mantenerce actualizados)


Porqué surge data science ahora y no antes?

	* La gran cantidad de datos que se generan cada minuto de cada dia.
	* El poder de procesamiento de datos que está disponible en este momento.



En que campos trabajan los data scientist?

	Para todos los campos actualemte todas las industrias buscan un cientifico de datos

	Datascientist de la academia: es el que hace las invetigaciones desde la academia. Para estos
		si es más necesaria la especialización universitaria.

	Datascientist de la industria: es que el trabaja en una empresa y enriquece la industria.



Cuales habilidades y herramientas usa un data scientist?
	
	* Matemáticas: Estadistica, Machine learning, Optimización (de procesos y datos)
	* Ingenieria: Python, R, Scala



	- El espacio del problema, Cuanto más lo entiendes mejor haces tu trabajo.

		Antes de escribir una sola línea de código hay que responder a las siguientes
			preguntas:

			* Cual es el objetivo? (tener claro el objetivo)
			* Cual es la pregunta exacta, que queremos modelar?
			* Como se define el exito? Debe nuestra predicción sobre pasar cierto nivel de
				confianza, a quienes se muestra la predicción?


		Es mejor pasar más tiempo entendiendo el problema que programando.


Configurando un notebook

	>>> pip install jupyter (para installar jupyter notebook)


	- https://www.kaggle.com/datasets (para descargar datasets)


	>>> jupyter notebook		# para lanzar el notebook

	- Para ejecutar comandos de terminal desde el notebook usar el signo '!'

			>>> !pip install pandas

	DATAFRAME: Serie de datos organizados en filas y columnas.

	Panda series: es el tipo de dato de cada columna.

	----- En el notebook (pokemon-exploracion)

	"Trabajando con un Pandas 'Series'"

		data['Name']		# muestra los datos de la columna 'Name'
		data.Name 			# tambien muestra los datos de la columna 'Name'
		type(data['Name'])	# muestra el tipo de dato



Guía de jupyter
	
	Que es?:
	 	Es un entorno de desarrollo interactivo agnóstico del lenguaje para ciencias 
	 	de la computación y ciencia de datos.

	Tiene tres componentes:
		* Aplicación web, para correr código de forma interactiva desde un navegador 
			web.
		* Kernels, el proceso que corre el código en el lenguaje especifico y regresa
			las salida del proceso a la aplicación web, jupyter soporta varios lenguajes:
			python, julia, R ...
		* Documentos, código, anotaciones, imágenes, video que compone el notebook, son 
			almacenados en formato JSON.


	Jupyter dashboard
		Encontramos tres pestañas:
			Files: archivos del proyecto (muestra los archivos del directorio actual 
											de la terminal).

			Running: Procesos que se encuentran corriendo.
			Cluster: Administrador de los procesos en paralelo.

		Y dos botones:
			Upload: Cargar archivos del computador.
			New: Crear nuevo archivo de texto, folder, terminal o notebook, en este ultimo
			lista los lenguajes con los cuales podemos crearlo.


		Interfaz:
			Al crear un nuevo notebook (con el botón 'new') aparecen dos cintas dos
			opciones:

				* Header: Menú donde se encuentran las opciones de edición y ejecución,
					siempre estara fijo.
				* Body: Es el lugar de trabajo, se compone de celdas que pueden ser de 3 
					tipos:

						- Markdown: Para crear textos con formato que sirvan como guía en
							el notebook.
						- Código: Se define el código que se va a ejecutar.
						- Celdas sin formato: Cuando se necesita incluir texto sin formato.

						En las celda de tipo código para ejecutar podemos usar: ctrl + espacio, 
						y si queremos ejecutar y crear una nueva celda: shift + espacio.


						Con 'tab' se activa el autocompletado.




Continuando con nuestro ejemplo:

	La libreria 'seaborn' crea visualizacione informativas (graficos)


Flujo de trabajo de un data scientist
	
	La principal lavor es encontrar valor para las empresas o personas a través de datos, para esto
	se debe seguir un flujo de trabajo que logre convertir estos datos en información significativa.

	El flujo de trabajo se divide en 6 pasos:

		1. Decidir los objetivos: 
			Como primer paso se deben definir los objetivos de nuestro proceso, estos generalmente
			se definen con preguntas.

			Los objetivos deben ser claros, medibles y concisos. Hay que tener cuidado con esto ya 
			que todo el proceso depende de una buena definición de los objetivos.

			La naturaleza de los datos y el proceso va a diferir del tipo de objetivos o preguntas 
			que se planteen.

		2. Establecer prioridades de medición:
			Cuando este definidos los objetivos, se debe establecer que se debe medir basado en los
			objetivos propuestos.

			Se debe tener claro se necesitan para lograr el objetivo.

			- Decidir como medir: Es importante decidir que parametros se van a usar para medir los
							datos antes de empezar a recolectarlos, como se midan los datos juega 
							un rol importante en el analisis de los mismos.

		3. Recolección de datos: 
			Cuando ya se tienen las prioridades y lo parametros para medir, es más facil recolectar
			los datos.

		4. Limpieza de datos:
			Los datos que se han recolectado no son necesariamene útiles, en este proceso se debe asegurar que los datos menos útiles no se encuentren en la fase de análisis.

			Cuando se tienen datos no deseados en el sistema, se puede afectar la calidad de las
			decisiones. Tener datos de calidad es importante para tomar mejores decisiones, este
			proceso requiere bastante tiempo por lo que es buena idea automatizar el proceso.

		5. Analisis de datos:
			Cuando se tiene los datos necesarios, es tiempo de procesarlos.

		6. Interpretación y comunicación de resultados:
			Una vez se han analizado los datos, es tiempo de interpretar los resultados y comunicarlos
			a las personas involucradas dentro de la empresa.

	

